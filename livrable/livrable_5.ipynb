{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIVRABLE PROJET PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INPUT\n",
    "1) Import des libraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Création des dataframes à partir des fichiers csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv():\n",
    "\n",
    "    notebook_dir = os.getcwd()                          #Chemin absolu du notebook\n",
    "    data_dir = os.path.join(notebook_dir, \"../data\")    #Construction du chemin absolu vers le dossier 'data'\n",
    "    csv_files = os.listdir(data_dir)                    #Liste des fichiers dans le dossier 'data'\n",
    "\n",
    "    dataframes_dict = {}                                #Déclaration dictionnaire pour contenir les dataframes\n",
    "    \n",
    "    for file in csv_files:                              #Boucle pour chaque fichier .csv du dossier 'data' : \n",
    "        if file.endswith('.csv'):\n",
    "            \n",
    "            file_path = os.path.join(data_dir, file) \n",
    "            df = pd.read_csv(file_path)                         #Création du dataframe\n",
    "\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            dataframes_dict['df_' + str(file_name)] = df        #Renommage du dataframe avec préfixe \"df_\" + 'nom_du_fichier'\n",
    "            \n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])   #Conversion 'timestamp' en type Datetime    \n",
    "\n",
    "            print(f\"df_{file_name}\")                            #Affichage du df créé pour vérification\n",
    "            print(df.head(3))   \n",
    "            print(\"\\n\")\n",
    "\n",
    "    return dataframes_dict\n",
    "\n",
    "dataframes_dict = load_data_from_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MANIPULATION DES DONNEES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Création d'un dataframe 'df_all' et intégration dans le dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def global_df_creation(): \n",
    "    \n",
    "    dfs_to_concat = list(dataframes_dict.values())      #Identification des dataframes à concaténer\n",
    "    print(f\"Concaténation des dataframes :\\n{list(dataframes_dict)}\\n\")\n",
    "    \n",
    "    df_all = pd.concat(dfs_to_concat, ignore_index=True)        #Concaténation verticale -> pas de perte de données avec la fonction concat, redéfinition des index pour avoir une clé unique par transaction\n",
    "    print(\"'df_all' :\")     \n",
    "    display(df_all)     #Vérification : '2021-02-24 23:59:52.000' *2 dans le display = transactions conservées      \n",
    "\n",
    "    dataframes_dict['df_all']= df_all       #Intégration de 'df_all' dans le dictionnaire\n",
    "    print(f\"Intégration dans le dictionnaire :\\n{list(dataframes_dict)}\\n\")     \n",
    "    \n",
    "global_df_creation() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CALCUL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Agrégation des données et calcul selon paramètres sélectionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_SELECTION_DES_PARAMETRES_#\n",
    "\n",
    "def select_time_ladder(initial_frequency='60min'): #Widget select 'frequency'\n",
    "    options = ['60min', '30min', '5min']                                                                        \n",
    "    dropdown_ladder = widgets.Dropdown(options=options, description='Interval:', value=initial_frequency)       #Création du widget de sélection\n",
    "    \n",
    "    def on_change(change):   #Update\n",
    "        if change['type'] == 'change' and change['name'] == 'value':        #En cas de changement de sélection, la nouvelle valeur correspond à la valeur sélectionnée\n",
    "            clear_output()                                                  #Nettoyage pour MàJ affichage\n",
    "            aggregation(dropdown_ladder.value, dropdown_vwmp_type.value)    #Aggrégation des données avec paramètres sélectionnés en tant qu'arguments\n",
    "                \n",
    "    dropdown_ladder.observe(on_change)      #Observation du changement de sélection\n",
    "    return dropdown_ladder\n",
    "\n",
    "def select_vwmp_type(initial_vwmp_type='lower'):    #Widget select 'vwmp_type'\n",
    "    options = ['lower', 'upper']                                                                                    \n",
    "    dropdown_vwmp_type = widgets.Dropdown(options=options, description='VWMP:', value=initial_vwmp_type)        #Création du widget de sélection\n",
    "    \n",
    "    def on_change(change):      #Update\n",
    "       if change['type'] == 'change' and change['name'] == 'value':         #En cas de changement de sélection, la nouvelle valeur correspond à la valeur sélectionnée\n",
    "            clear_output()                                                  #Nettoyage pour MàJ affichage\n",
    "            aggregation(dropdown_ladder.value, dropdown_vwmp_type.value)    #Aggrégation des données avec paramètres sélectionnés en tant qu'arguments\n",
    "            \n",
    "    dropdown_vwmp_type.observe(on_change)       #Observation du changement de sélection\n",
    "    return dropdown_vwmp_type\n",
    "\n",
    "#_AGGREGATION_#\n",
    "\n",
    "def aggregation(frequency, vwmp_type):      #Boucles de manipulations des dataframes (1 boucle calcul + 1 boucle cleaning)\n",
    "    \n",
    "    print(\"...calcul en cours\")\n",
    "    aggregated_dict = {}                        \n",
    "\n",
    "    for key, df in dataframes_dict.items():     #Boucle de calcul (B1)\n",
    "        aggregated_df = process_dataframe(key, df, frequency, vwmp_type) \n",
    "        aggregated_dict[key] = aggregated_df     \n",
    "\n",
    "    for key, df in aggregated_dict.items():     #Boucle de cleaning (B2)\n",
    "        cleaned_df = cleaning(df) \n",
    "        cleaned_dict[key] = cleaned_df \n",
    "\n",
    "    clear_output()\n",
    "    visualisation(cleaned_dict)     #Fonction d'affichage des résultats sous forme de graphique en chandelier japonais + widgets de sélection\n",
    "\n",
    "    return cleaned_dict\n",
    "  \n",
    "##__Boucle_1__## \n",
    "\n",
    "def process_dataframe(key, df, frequency, vwmp_type):   #Structure de calcul du dataframe\n",
    "    \n",
    "    exchange_name_splitted = (str(key)).split(\"df_\")        #Extraction du nom de l'exchange\n",
    "    exchange_name = exchange_name_splitted[1]\n",
    "\n",
    "    df['weighted_volume'] = (df['price'] * df['amount'])        #Calcul du Weighted_Volume de chaque transaction avant agréggation\n",
    "\n",
    "    aggregated_df = initial_aggregation(df, frequency)      #Agrégation des transactions initiales\n",
    "\n",
    "    aggregated_df[f'{exchange_name}_vwap'] = df.groupby(pd.Grouper(key='timestamp', freq=frequency)).apply(calculate_vwap)                                           #Calcul du Volume Weighted Average Price [VWAP] \n",
    "    aggregated_df['ecart_type'] = df.groupby(pd.Grouper(key='timestamp', freq=frequency)).apply(calculate_ecart_type)                                                #Calcul de l'écart_type \n",
    "    aggregated_df[f'vwmp_{vwmp_type}'] = df.groupby(pd.Grouper(key='timestamp', freq=frequency)).apply(lambda group: pd.Series(calculate_vwmp(group, vwmp_type)))    #Calcul du Volume Weighted Median Price [VWMP (lower or upper)] \n",
    "\n",
    "    return aggregated_df \n",
    "\n",
    "def initial_aggregation(df, frequency):     #Aggrégation initiale des transactions                          \n",
    "            \n",
    "    aggregated_df = df.groupby(pd.Grouper(key='timestamp', freq=frequency)).agg({    #Fonctions d'agrégation pour chaque colonnes\n",
    "        'price': ['sum', 'first', 'max', 'min', 'last'],             \n",
    "        'amount': 'sum',\n",
    "        'weighted_volume': 'sum'\n",
    "    })\n",
    "\n",
    "    aggregated_df.columns = [       #Renommage des colonnes\n",
    "                            'price', 'price_open', 'price_high', 'price_low', 'price_close',\n",
    "                            'amount',\n",
    "                            'weighted_volume'\n",
    "    ]\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "def calculate_vwap(group):      #Calcul du Volume Weighted Average Price [VWAP]   \n",
    "    sum_price_amount = group['weighted_volume'].sum()                                           \n",
    "    sum_amount = group['amount'].sum()\n",
    "\n",
    "    if sum_amount != 0:\n",
    "        return sum_price_amount / sum_amount \n",
    "    else : \n",
    "        return 0    \n",
    "\n",
    "def calculate_ecart_type(group):        #Calcul de l'écart_type\n",
    "    \n",
    "    ecart_type = np.nanstd(group['price'])      #'np.nanstd' pour exclure les valeurs nulles dans le calcul de l'écart type \n",
    "    if ecart_type != np.nan :\n",
    "        return ecart_type\n",
    "    else : \n",
    "        return 0        #écart type à zéro dans le cas d'un échantillon de taille 1 (une seule valeur de 'price' sur la période)\n",
    "\n",
    "def calculate_vwmp(group, vwmp_type):  #Calcul du Volume Weighted Median Price [VWMP (lower or upper)] \n",
    "\n",
    "    series_sorted = group.sort_values('amount')                         #Tri du volume par ordre croissant\n",
    "    series_sorted['cumul_amount'] = series_sorted['amount'].cumsum()    #Calcul du volume cumulé\n",
    "    total_volume_median = series_sorted['cumul_amount'].max() / 2       #Calcul de la médiane\n",
    "    #--------\n",
    "    if vwmp_type == 'lower':    #LOWER\n",
    "       \n",
    "        lower_cumulative_volume = series_sorted[series_sorted['cumul_amount'] <= total_volume_median]   #Filtrage de la série pour conserver la partie inférieure (>=) du volume cumulé \n",
    "       \n",
    "        if not lower_cumulative_volume.empty:   #Si la taille de l'échantillon est >> 2\n",
    "           \n",
    "            max_cumul_amount_index = lower_cumulative_volume['cumul_amount'].idxmax()   #Identification de la ligne correspondante au volume cumulé maximum de la série filtrée (ensemble inférieure)\n",
    "            vwmp_lower = group.loc[max_cumul_amount_index, 'price']                     #Déduction du prix médian bas pondéré par le volume\n",
    "            return vwmp_lower  \n",
    "        \n",
    "        else : \n",
    "            return group['price'].mean()    #Cas particuliers (mesuré x3 occurences) soit (vwmp = price si échantillon = 1 ;  vwmp = 0 si échantillon = 0) -> utilisation de la fonction mean pour renvoyer ce résultat\n",
    "\n",
    "    #-- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - #symétrie\n",
    "\n",
    "    if vwmp_type == 'upper':    #UPPER\n",
    "    \n",
    "        upper_cumulative_volume = series_sorted[series_sorted['cumul_amount'] <= total_volume_median]   #Filtrage de la série pour conserver la partie inférieure (>=) du volume cumulé \n",
    "    \n",
    "        if not upper_cumulative_volume.empty:   #Si la taille de l'échantillon est >> 2\n",
    "       \n",
    "            min_cumul_amount_index = upper_cumulative_volume['cumul_amount'].idxmin()   #Identification de la ligne correspondante au volume cumulé maximum de la série filtrée (ensemble inférieure)\n",
    "            vwmp_upper = group.loc[min_cumul_amount_index, 'price']                     #Déduction du prix médian bas pondéré par le volume\n",
    "            return vwmp_upper  \n",
    "    \n",
    "        else : \n",
    "            return group['price'].mean()    #Cas particuliers (mesuré x3 occurences) soit (vwmp = price si échantillon = 1 ;  vwmp = 0 si échantillon = 0) -> utilisation de la fonction mean pour renvoyer ce résultat\n",
    "    #----------\n",
    "    else:\n",
    "        raise ValueError(\"Mode non valide. Veuillez spécifier 'lower' ou 'upper'.\")\n",
    "\n",
    "##__Boucle_2__## \n",
    "\n",
    "def cleaning(df):   #Supprime les lignes vides (pas de transactions dans un intervalle de temps)\n",
    "    \n",
    "    df_cleaned = df.copy()                                                      #Copie pour ne pas modifier le df original\n",
    "    df_cleaned = df_cleaned[~df_cleaned.apply(                                  #Filtrage des lignes où toutes les valeurs sont nulles\n",
    "        lambda row: all(val == 0.0 or pd.isnull(val) for val in row), axis=1    \n",
    "    )] \n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "#_VISUALISE_#\n",
    "       \n",
    "def visualisation(cleaned_dict):    #Boucle de création de graphique\n",
    "    \n",
    "    # WIDGETS # \n",
    "    grid = widgets.GridspecLayout(1, 10) \n",
    "    grid[0, 0] = export_button\n",
    "    grid[0, 1] = dropdown_ladder\n",
    "    grid[0, 2] = dropdown_vwmp_type\n",
    "    display(grid)  \n",
    "       \n",
    "    for key, df in reversed(list(cleaned_dict.items())):        #Boucle de création de graphique pour chaque dataframe\n",
    "    \n",
    "        exchange_name_splitted = (str(key)).split(\"df_\")        #Extraction du nom de l'exchange\n",
    "        exchange_name = exchange_name_splitted[1]\n",
    "\n",
    "        candlestick = go.Figure(data=[go.Candlestick(x=df.index, #Création d'un graphique en chandelier japonais \n",
    "                                                      open=df['price_open'],\n",
    "                                                      high=df['price_high'],\n",
    "                                                      low=df['price_low'],\n",
    "                                                      close=df['price_close']\n",
    "                                                     )])\n",
    "\n",
    "        candlestick.update_layout(title=f'Exchange - [{exchange_name}]', #Mise à jour du graphique\n",
    "                                  yaxis_title='Price',\n",
    "                                  height=300,  \n",
    "                                  width=800,   \n",
    "                                  margin=dict(l=70, r=50, t=50, b=20)\n",
    "                                  )\n",
    "       \n",
    "        candlestick.add_trace(go.Scatter(x=df.index, y=df[f'{exchange_name}_vwap'], mode='lines', name='VWAP', line_color='blue'))      #Ajout courbe du Volume Weighted Average Price [VWAP]\n",
    "        \n",
    "        column_index = 9                                                                                                                #Index de la colonne 'vwmp_XXXer'(10ème colonne)\n",
    "        column_name = df.columns[column_index]                                                                                          #Nom de la colonne 'vwmp_upper' ou 'vwmp_lower' \n",
    "        candlestick.add_trace(go.Scatter(x=df.index, y=df.iloc[:, column_index], mode='lines', name=column_name, line_color='grey'))    #Ajout courbe du Volume Weighted Median Price [VWMP] avec nom de série associé\n",
    "        \n",
    "        candlestick.show()      #Affichage du graphique crée pour le dataframe\n",
    "    \n",
    "    \n",
    "#_EXPORT_CSV_#\n",
    "\n",
    "def export_csv(export_folder):      #Fonction en cas de clic sur le wigdget 'Exporter en csv'\n",
    "    \n",
    "    concatenated_dict = {}                                  #Dictionnaire concaténé = cleaned_dict + 'synthese'     \n",
    "    concatenated_dict = concatenate_output(cleaned_dict)    #Remplissage de concatenated_dict avec la fonction \"concatenate_output\"\n",
    "\n",
    "    for key, df in concatenated_dict.items():   \n",
    "\n",
    "        filename = (f\"{key}.csv\")                   #ID du fichier csv = nom du dataframe\n",
    "        file_path = export_folder + filename        #Chemin de l'enregistrement\n",
    "        df.to_csv(file_path, index=True)            #enregistre le dataframe en fichier .csv\n",
    "    \n",
    "    print(f\"Export des fichiers csv avec succès (voir arborescence ci-dessous): {export_folder}\")\n",
    "\n",
    "    return concatenated_dict \n",
    "\n",
    "def concatenate_output(cleaned_dict):       #Assemblage des résultats dans un dataframe 'synthese' \n",
    "    \n",
    "    df_output = None    #Déclaration d'un dataframe vide\n",
    "    \n",
    "    for key, df in cleaned_dict.items():        \n",
    "        \n",
    "        exchange_name_splitted = (str(key)).split(\"df_\")   #Extraction du nom de l'exchange dans le nom du dataframe\n",
    "        exchange_name = exchange_name_splitted[1]\n",
    "                        \n",
    "        if f'{exchange_name}_vwap' in df.columns:          #Check si la colonne 'vwap' existe dans le dataframe \n",
    "            \n",
    "            vwap_column = df[f'{exchange_name}_vwap']      #Identifie la colonne 'wvap' de l'exchange\n",
    "                        \n",
    "            if df_output is None:                          #1ère itération\n",
    "               df_output = vwap_column.to_frame()          #Copie de la colonne 'vwap' de l'exchange et intégration au dataframe de synthese\n",
    "            else:\n",
    "               df_output = pd.concat([df_output, vwap_column], axis=1)  #itération >= 2 : concaténe la colonne 'wvap' de l'exchange au dataframe de synthese\n",
    "    \n",
    "        concatenated_dict = cleaned_dict.copy()            #Duplication du dictionnaire d'entrée\n",
    "        concatenated_dict['synthese'] = df_output          #Intégration du dataframe 'synthese' dans le nouveau dictionnaire\n",
    "        \n",
    "    return concatenated_dict\n",
    "\n",
    "def on_export_button_click(b):      #Widget pour export csv\n",
    "    \n",
    "    notebook_dir = os.getcwd()                              #Chemin du notebook\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")      #Timestamp du lancement export\n",
    "    export_folder = (notebook_dir) + '/../output/Export_' + (now) + '_freq-'+ (dropdown_ladder.value) + '_vwmp-' + (dropdown_vwmp_type.value) +'/'      #Création d'un dossier 'export' horodaté avec les paramètres sélectionnées à l'export\n",
    "    \n",
    "    os.mkdir(export_folder)         #Création du dossier 'Export_YYYY-MM-DD_HH-MM-SS_freq-Xmin_vwmp-X'\n",
    "    export_csv(export_folder)       #Appel fonction 'export csv' \n",
    "\n",
    "export_button = widgets.Button(description=\"Exporter en CSV\")\n",
    "\n",
    "#_INITIALISATION_#\n",
    "\n",
    "cleaned_dict = {}    #Dictionnaire des données agrégées et nettoyées\n",
    "\n",
    "dropdown_ladder = select_time_ladder()              #init selection 'frequency' par défault\n",
    "dropdown_vwmp_type = select_vwmp_type()             #init selection 'vwmp_type' par défaut\n",
    "export_button.on_click(on_export_button_click)      #init button_click pour exporter en csv\n",
    "\n",
    "aggregation(dropdown_ladder.value, dropdown_vwmp_type.value)    #initialisation par défaut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESULTATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas où les widgets ne fonctionnerait pas dans le jupyter notebook :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Lancer l'aggrégation avec les paramètres souhaités et visualiser les résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation('60min', 'lower')   \n",
    "\n",
    "    #agg1 : ('60min', '30min', '5min')\n",
    "    #agg2 : ('lower', 'upper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Exporter les données avec les paramètres sélectionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =True\n",
    "on_export_button_click(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arborescence du projet : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  .\n",
    "##  ├── data\n",
    "##  │   ├── bfly.csv\n",
    "##  │   ├── bfnx.csv\n",
    "##  │   ├── bnus.csv\n",
    "##  │   ├── btrx.csv\n",
    "##  │   ├── cbse.csv\n",
    "##  │   ├── gmni.csv\n",
    "##  │   ├── itbi.csv\n",
    "##  │   ├── krkn.csv\n",
    "##  │   ├── lmax.csv\n",
    "##  │   ├── okcn.csv\n",
    "##  │   └── stmp.csv\n",
    "##  ├── livrable\n",
    "##  │   └── livrable.ipynb\n",
    "##  ├── output\n",
    "##  │   ├── Export_YYYY-MM-DD_HH-MM-SS_freq-Xmin_vwmp-X\n",
    "##  │   │   ├── df_all.csv\n",
    "##  │   │   ├── df_bfly.csv\n",
    "##  │   │   ├── df_bfnx.csv\n",
    "##  │   │   ├── df_bnus.csv\n",
    "##  │   │   ├── df_btrx.csv\n",
    "##  │   │   ├── df_cbse.csv\n",
    "##  │   │   ├── df_gmni.csv\n",
    "##  │   │   ├── df_itbi.csv\n",
    "##  │   │   ├── df_krkn.csv\n",
    "##  │   │   ├── df_lmax.csv\n",
    "##  │   │   ├── df_okcn.csv\n",
    "##  │   │   ├── df_stmp.csv\n",
    "##  │   │   └── synthese.csv\n",
    "##  └── readme.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
