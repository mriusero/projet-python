{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIVRABLE PROJET PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INPUT\n",
    "1) Import des libraires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Création des dataframes à partir des fichiers csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_stmp\n",
      "            timestamp    price  amount\n",
      "0 2021-02-24 23:59:54  49754.0   0.753\n",
      "1 2021-02-24 23:59:52  49754.0   0.116\n",
      "2 2021-02-24 23:59:52  49754.0   0.104\n",
      "\n",
      "\n",
      "df_lmax\n",
      "                timestamp    price  amount\n",
      "0 2021-02-24 23:59:59.691  49767.0    0.01\n",
      "1 2021-02-24 23:59:42.786  49752.0    0.06\n",
      "2 2021-02-24 23:59:42.785  49752.0    0.30\n",
      "\n",
      "\n",
      "df_gmni\n",
      "                timestamp     price    amount\n",
      "0 2021-02-24 23:59:53.406  49773.07  0.003435\n",
      "1 2021-02-24 23:59:53.406  49766.06  0.051690\n",
      "2 2021-02-24 23:59:47.280  49746.16  0.122833\n",
      "\n",
      "\n",
      "df_itbi\n",
      "                timestamp     price  amount\n",
      "0 2021-02-24 23:59:48.157  49753.50  0.0001\n",
      "1 2021-02-24 23:59:45.463  49753.75  0.0004\n",
      "2 2021-02-24 23:59:38.887  49734.50  0.0001\n",
      "\n",
      "\n",
      "df_okcn\n",
      "                timestamp     price  amount\n",
      "0 2021-02-24 23:59:57.847  49724.93    0.02\n",
      "1 2021-02-24 23:59:49.743  49730.33    0.02\n",
      "2 2021-02-24 23:59:35.623  49706.87    0.02\n",
      "\n",
      "\n",
      "df_bfnx\n",
      "                timestamp    price  amount\n",
      "0 2021-02-24 23:59:58.181  49716.0   0.010\n",
      "1 2021-02-24 23:59:58.176  49713.0   0.005\n",
      "2 2021-02-24 23:59:51.526  49715.0   0.005\n",
      "\n",
      "\n",
      "df_btrx\n",
      "                timestamp      price    amount\n",
      "0 2021-02-24 23:59:48.910  49742.749  0.001054\n",
      "1 2021-02-24 23:59:35.050  49734.460  0.009038\n",
      "2 2021-02-24 23:59:34.110  49751.270  0.000386\n",
      "\n",
      "\n",
      "df_bfly\n",
      "                timestamp     price  amount\n",
      "0 2021-02-24 23:59:33.720  49712.15  0.0054\n",
      "1 2021-02-24 23:44:16.980  49603.44  0.0770\n",
      "2 2021-02-24 22:32:39.320  48864.19  0.1200\n",
      "\n",
      "\n",
      "df_bnus\n",
      "                timestamp     price    amount\n",
      "0 2021-02-24 23:59:58.164  49714.50  0.004413\n",
      "1 2021-02-24 23:59:57.547  49727.83  0.001496\n",
      "2 2021-02-24 23:59:57.244  49727.83  0.002597\n",
      "\n",
      "\n",
      "df_cbse\n",
      "                timestamp     price   amount\n",
      "0 2021-02-24 23:59:59.873  49737.82  0.00144\n",
      "1 2021-02-24 23:59:59.721  49737.82  0.00037\n",
      "2 2021-02-24 23:59:59.121  49737.82  0.00294\n",
      "\n",
      "\n",
      "df_krkn\n",
      "                timestamp    price    amount\n",
      "0 2021-02-24 23:59:58.649  49727.7  0.000225\n",
      "1 2021-02-24 23:59:49.807  49739.9  0.000224\n",
      "2 2021-02-24 23:59:43.159  49736.3  0.014493\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_csv():\n",
    "\n",
    "    notebook_dir = os.getcwd()        \n",
    "                      #Chemin absolu du notebook\n",
    "    data_dir = os.path.join(notebook_dir, \"../data\")    #Construction du chemin absolu vers le dossier 'data'\n",
    "    csv_files = os.listdir(data_dir)                    #Liste des fichiers dans le dossier 'data'\n",
    "\n",
    "    dataframes_dict = {}                                #Déclaration dictionnaire pour contenir les dataframes\n",
    "    \n",
    "    for file in csv_files:                              #Boucle pour chaque fichier .csv du dossier 'data' : \n",
    "        if file.endswith('.csv'):\n",
    "            \n",
    "            file_path = os.path.join(data_dir, file) \n",
    "            df = pd.read_csv(file_path)                         #Création du dataframe\n",
    "\n",
    "            file_name = os.path.splitext(file)[0]\n",
    "            dataframes_dict['df_' + str(file_name)] = df        #Renommage du dataframe avec préfixe \"df_\" + 'nom_du_fichier'\n",
    "            \n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])   #Conversion 'timestamp' en type Datetime    \n",
    "\n",
    "            print(f\"df_{file_name}\")                            #Affichage du df créé pour vérification\n",
    "            print(df.head(3))   \n",
    "            print(\"\\n\")\n",
    "\n",
    "    return dataframes_dict\n",
    "\n",
    "dataframes_dict = load_data_from_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MANIPULATION DES DONNEES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Création d'un dataframe 'df_all' et intégration dans le dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concaténation des dataframes :\n",
      "['df_stmp', 'df_lmax', 'df_gmni', 'df_itbi', 'df_okcn', 'df_bfnx', 'df_btrx', 'df_bfly', 'df_bnus', 'df_cbse', 'df_krkn']\n",
      "\n",
      "'df_all' :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>price</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-24 23:59:54.000</td>\n",
       "      <td>49754.0</td>\n",
       "      <td>0.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-24 23:59:52.000</td>\n",
       "      <td>49754.0</td>\n",
       "      <td>0.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-24 23:59:52.000</td>\n",
       "      <td>49754.0</td>\n",
       "      <td>0.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-24 23:59:49.000</td>\n",
       "      <td>49754.0</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-24 23:59:45.000</td>\n",
       "      <td>49754.0</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136788</th>\n",
       "      <td>2021-02-24 00:00:11.182</td>\n",
       "      <td>48899.8</td>\n",
       "      <td>0.023270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136789</th>\n",
       "      <td>2021-02-24 00:00:10.373</td>\n",
       "      <td>48899.9</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136790</th>\n",
       "      <td>2021-02-24 00:00:07.818</td>\n",
       "      <td>48899.9</td>\n",
       "      <td>0.018278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136791</th>\n",
       "      <td>2021-02-24 00:00:02.351</td>\n",
       "      <td>48899.9</td>\n",
       "      <td>0.002045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136792</th>\n",
       "      <td>2021-02-24 00:00:01.115</td>\n",
       "      <td>48899.6</td>\n",
       "      <td>0.018780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1136793 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp    price    amount\n",
       "0       2021-02-24 23:59:54.000  49754.0  0.753000\n",
       "1       2021-02-24 23:59:52.000  49754.0  0.116000\n",
       "2       2021-02-24 23:59:52.000  49754.0  0.104000\n",
       "3       2021-02-24 23:59:49.000  49754.0  0.016000\n",
       "4       2021-02-24 23:59:45.000  49754.0  0.011000\n",
       "...                         ...      ...       ...\n",
       "1136788 2021-02-24 00:00:11.182  48899.8  0.023270\n",
       "1136789 2021-02-24 00:00:10.373  48899.9  0.200000\n",
       "1136790 2021-02-24 00:00:07.818  48899.9  0.018278\n",
       "1136791 2021-02-24 00:00:02.351  48899.9  0.002045\n",
       "1136792 2021-02-24 00:00:01.115  48899.6  0.018780\n",
       "\n",
       "[1136793 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intégration dans le dictionnaire 'all_dataframes_dict' :\n",
      "['df_stmp', 'df_lmax', 'df_gmni', 'df_itbi', 'df_okcn', 'df_bfnx', 'df_btrx', 'df_bfly', 'df_bnus', 'df_cbse', 'df_krkn', 'df_all']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def global_df_creation(dataframes_dict): \n",
    "    \n",
    "    dfs_to_concat = list(dataframes_dict.values())      #Identification des dataframes à concaténer\n",
    "    print(f\"Concaténation des dataframes :\\n{list(dataframes_dict)}\\n\")\n",
    "    \n",
    "    df_all = pd.concat(dfs_to_concat, ignore_index=True)        #Concaténation verticale -> pas de perte de données avec la fonction concat, redéfinition des index pour avoir une clé unique par transaction\n",
    "    print(\"'df_all' :\")     \n",
    "    display(df_all)     #Vérification : '2021-02-24 23:59:52.000' *2 dans le display = transactions conservées      \n",
    "\n",
    "    all_dataframes_dict = dataframes_dict.copy()\n",
    "    all_dataframes_dict['df_all'] = df_all\n",
    "    print(f\"Intégration dans le dictionnaire 'all_dataframes_dict' :\\n{list(all_dataframes_dict)}\\n\")\n",
    "\n",
    "    return all_dataframes_dict\n",
    "    \n",
    "all_dataframes_dict = global_df_creation(dataframes_dict) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CALCUL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Définition des paramètres de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_values():\n",
    "\n",
    "    frequency = '60min'\n",
    "    vwmp_type = 'lower' \n",
    "    \n",
    "    return frequency, vwmp_type "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Agrégation des données et calcul selon paramètres sélectionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(all_dataframes_dict, frequency, vwmp_type):                     #PROCESS DE CALCUL :                                                    \n",
    "    \n",
    "    print(\"...calcul en cours\")\n",
    "    \n",
    "    aggregated_dict = {}        #Données initiales aggrégées (1)\n",
    "    calculated_dict = {}        #Données calculées (vwap, ecart_type, vwmp) (2)\n",
    "    cleaned_dict = {}           #Données nettoyées (suppression des lignes vides) (3)\n",
    "    compilated_dict = {}        #Compilation des résultats (création du 'df_synthese') (4)                  \n",
    "\n",
    "    for key, df in all_dataframes_dict.items():                                         \n",
    "\n",
    "        exchange_name = (str(key)).split(\"df_\")[1]                                  \n",
    "        \n",
    "        aggregated_df = aggregate_data(df, frequency)     #(1)Aggréggation des données initiales\n",
    "        aggregated_dict[key] = aggregated_df \n",
    "        \n",
    "        calculated_df = calculate_metrics(df, frequency, vwmp_type, aggregated_df, exchange_name)       #(2)Calcul des métriques\n",
    "        calculated_dict[key] = calculated_df \n",
    "                \n",
    "        cleaned_df = clean_data(calculated_df)            #(3)Suppression des lignes vides\n",
    "        cleaned_dict[key] = cleaned_df\n",
    "\n",
    "    compilated_dict = compilate_data(cleaned_dict)        #(4)Compilation des résultats dans un 'df_synthese'\n",
    "      \n",
    "    return aggregated_dict, calculated_dict, cleaned_dict, compilated_dict\n",
    "\n",
    "def aggregate_data(df, frequency):                                               #(1) Aggrégation des données initiales (Price, Amount)                  \n",
    "    \n",
    "    df['weighted_volume'] = (df['price'] * df['amount'])        #Calcul du Weighted_Volume de chaque transaction avant agréggation \n",
    "\n",
    "    aggregated_df = df.groupby(pd.Grouper(key='timestamp', freq=frequency)).agg({    #Fonctions d'agrégation pour chaque colonnes\n",
    "        'price': ['sum', 'first', 'max', 'min', 'last'],   \n",
    "        'amount': 'sum',\n",
    "        'weighted_volume': 'sum'\n",
    "    })\n",
    "\n",
    "    aggregated_df.columns = ['price', 'price_open', 'price_high', 'price_low', 'price_close','amount','weighted_volume']        #Renommage des colonnes\n",
    "    \n",
    "    return aggregated_df\n",
    "\n",
    "def calculate_metrics(df, frequency, vwmp_type, aggregated_df, exchange_name):   #(2) Calcul des métriques (VWAP, VWMP, ecart_type)                      \n",
    "    \n",
    "    calculated_df = aggregated_df     \n",
    "\n",
    "    calculated_df[f'{exchange_name}_vwap'] = df.groupby(pd.Grouper(key='timestamp', freq=frequency)).apply(calculate_vwap)                                           #Calcul du Volume Weighted Average Price [VWAP] \n",
    "    calculated_df['ecart_type'] = df.groupby(pd.Grouper(key='timestamp', freq=frequency)).apply(calculate_ecart_type)                                                #Calcul de l'écart_type \n",
    "    calculated_df[f'vwmp_{vwmp_type}'] = df.groupby(pd.Grouper(key='timestamp', freq=frequency)).apply(lambda group: pd.Series(calculate_vwmp(group, vwmp_type)))    #Calcul du Volume Weighted Median Price [VWMP (lower or upper)] \n",
    "\n",
    "    return calculated_df \n",
    "\n",
    "def calculate_vwap(group):                                                       #(2.1) Calcul du Volume Weighted Average Price [VWAP]                   \n",
    "    sum_price_amount = group['weighted_volume'].sum()                                           \n",
    "    sum_amount = group['amount'].sum()\n",
    "\n",
    "    if sum_amount != 0:\n",
    "        return sum_price_amount / sum_amount \n",
    "    else : \n",
    "        return 0    \n",
    "\n",
    "def calculate_ecart_type(group):                                                 #(2.2) Calcul de l'écart_type                                           \n",
    "    \n",
    "    ecart_type = np.nanstd(group['price'])      #'np.nanstd' pour exclure les valeurs nulles dans le calcul de l'écart type \n",
    "    if ecart_type != np.nan :\n",
    "        return ecart_type\n",
    "    else : \n",
    "        return 0        #écart type à zéro dans le cas d'un échantillon de taille 1 (une seule valeur de 'price' sur la période)\n",
    "\n",
    "def calculate_vwmp(group, vwmp_type):                                            #(2.3) Calcul du Volume Weighted Median Price [VWMP (lower or upper)]   \n",
    "\n",
    "    series_sorted = group.sort_values('amount')                         #Tri du volume par ordre croissant\n",
    "    series_sorted['cumul_amount'] = series_sorted['amount'].cumsum()    #Calcul du volume cumulé\n",
    "    total_volume_median = series_sorted['cumul_amount'].max() / 2       #Calcul de la médiane\n",
    "    \n",
    "    #--------\n",
    "    if vwmp_type == 'lower':    #LOWER\n",
    "       \n",
    "        lower_cumulative_volume = series_sorted[series_sorted['cumul_amount'] <= total_volume_median]   #Filtrage de la série pour conserver la partie inférieure (>=) du volume cumulé \n",
    "       \n",
    "        if not lower_cumulative_volume.empty:   #Si la taille de l'échantillon est >> 2\n",
    "           \n",
    "            max_cumul_amount_index = lower_cumulative_volume['cumul_amount'].idxmax()   #Identification de la ligne correspondante au volume cumulé maximum de la série filtrée (ensemble inférieure)\n",
    "            vwmp_lower = group.loc[max_cumul_amount_index, 'price']                     #Déduction du prix médian bas pondéré par le volume\n",
    "            return vwmp_lower  \n",
    "        \n",
    "        else : \n",
    "            return group['price'].mean()    #Cas particuliers (mesuré x3 occurences) soit (vwmp = price si échantillon = 1 ;  vwmp = 0 si échantillon = 0) -> utilisation de la fonction mean pour renvoyer ce résultat\n",
    "\n",
    "    #-- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - -- - #symétrie\n",
    "\n",
    "    if vwmp_type == 'upper':    #UPPER\n",
    "    \n",
    "        upper_cumulative_volume = series_sorted[series_sorted['cumul_amount'] <= total_volume_median]   #Filtrage de la série pour conserver la partie inférieure (>=) du volume cumulé \n",
    "    \n",
    "        if not upper_cumulative_volume.empty:   #Si la taille de l'échantillon est >> 2\n",
    "       \n",
    "            min_cumul_amount_index = upper_cumulative_volume['cumul_amount'].idxmin()   #Identification de la ligne correspondante au volume cumulé maximum de la série filtrée (ensemble inférieure)\n",
    "            vwmp_upper = group.loc[min_cumul_amount_index, 'price']                     #Déduction du prix médian bas pondéré par le volume\n",
    "            return vwmp_upper  \n",
    "    \n",
    "        else : \n",
    "            return group['price'].mean()    #Cas particuliers (mesuré x3 occurences) soit (vwmp = price si échantillon = 1 ;  vwmp = 0 si échantillon = 0) -> utilisation de la fonction mean pour renvoyer ce résultat\n",
    "    \n",
    "    #----------\n",
    "    else:\n",
    "        raise ValueError(\"Mode non valide. Veuillez spécifier 'lower' ou 'upper'.\")\n",
    "\n",
    "def clean_data(calculated_df):                                                   #(3) Supprime les lignes vides (intervalle de temps sans transaction)   \n",
    "    \n",
    "    cleaned_df = calculated_df.copy()                                           #Copie pour ne pas modifier le df original\n",
    "    cleaned_df = cleaned_df[~cleaned_df.apply(                                  #Filtrage des lignes où toutes les valeurs sont nulles\n",
    "        lambda row: all(val == 0.0 or pd.isnull(val) for val in row), axis=1    \n",
    "    )]               \n",
    "    return cleaned_df\n",
    "\n",
    "def compilate_data(cleaned_dict):                                                #(4) Assemblage des résultats dans un dataframe 'df_synthese'           \n",
    "    \n",
    "    df_synthese = None    #Déclaration d'un dataframe vide\n",
    "    \n",
    "    for key, df in cleaned_dict.items():        \n",
    "        \n",
    "        exchange_name = (str(key)).split(\"df_\")[1]           #Extraction du nom de l'exchange dans le nom du dataframe\n",
    "                                \n",
    "        if f'{exchange_name}_vwap' in df.columns:            #Check si la colonne 'vwap' existe dans le dataframe \n",
    "            \n",
    "            vwap_column = df[f'{exchange_name}_vwap']        #Identifie la colonne 'wvap' de l'exchange\n",
    "                        \n",
    "            if df_synthese is None:                          #1ère itération\n",
    "               df_synthese = vwap_column.to_frame()          #Copie de la colonne 'vwap' de l'exchange et intégration au dataframe de synthese\n",
    "            else:\n",
    "               df_synthese = pd.concat([df_synthese, vwap_column], axis=1)  #itération >= 2 : concaténe la colonne 'wvap' de l'exchange au dataframe de synthese\n",
    "    \n",
    "    compilated_dict = cleaned_dict.copy()                #Duplication du dictionnaire d'entrée\n",
    "    compilated_dict['df_synthese'] = df_synthese         #Intégration du dataframe 'synthese' dans le nouveau dictionnaire\n",
    "        \n",
    "    return compilated_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualisation(cleaned_dict):\n",
    "    \n",
    "    candlestick_dict = {}    \n",
    "\n",
    "    for key, df in reversed(list(cleaned_dict.items())):  #Lecture en reverse pour afficher le df_all en 1er\n",
    "    \n",
    "        exchange_name = (str(key)).split(\"df_\")[1]        #Extraction du nom de l'exchange\n",
    "        vwmp_column_index = 9                             #Index de la colonne 'vwmp_XXXer'(10ème colonne)\n",
    "        \n",
    "        candlestick = go.Figure(data=[go.Candlestick(x=df.index,                    #Création d'un graphique en chandelier japonais \n",
    "                                                      open=df['price_open'],\n",
    "                                                      high=df['price_high'],\n",
    "                                                      low=df['price_low'],\n",
    "                                                      close=df['price_close']\n",
    "                                                     )])\n",
    "\n",
    "        candlestick.update_layout(title=f'Exchange - [{exchange_name}]', yaxis_title='Price', height=300, width=800, margin=dict(l=70, r=50, t=50, b=20))      #Mise en forme du graphique\n",
    "        candlestick.add_trace(go.Scatter(x=df.index, y=df[f'{exchange_name}_vwap'], mode='lines', name='VWAP', line_color='blue'))                             #Ajout courbe du Volume Weighted Average Price [VWAP]\n",
    "        candlestick.add_trace(go.Scatter(x=df.index, y=df.iloc[:, vwmp_column_index], mode='lines', name=df.columns[vwmp_column_index], line_color='grey'))    #Ajout courbe du Volume Weighted Median Price [VWMP] avec nom de série associé\n",
    "        \n",
    "        candlestick_dict[exchange_name] = candlestick\n",
    "\n",
    "    for exchange, candlestick in candlestick_dict.items(): \n",
    "        \n",
    "        display(candlestick)\n",
    "\n",
    "    return candlestick_dict         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Concaténation des données et export csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_csv(compilated_dict, frequency, vwmp_type):      #Fonction en cas de clic sur le wigdget 'Exporter en csv'\n",
    "\n",
    "    notebook_dir = os.getcwd()                                                                                              #Chemin du notebook\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")                                                                      #Timestamp du lancement export\n",
    "    export_folder = (notebook_dir) + '/../output/Export_' + (now) + '_freq-'+ (frequency) + '_vwmp-' + (vwmp_type) +'/'     #Création d'un dossier 'export' horodaté avec les paramètres sélectionnées à l'export\n",
    "    os.mkdir(export_folder)                                                                                                 #Création du dossier 'Export_YYYY-MM-DD_HH-MM-SS_freq-Xmin_vwmp-X'\n",
    "                                                                                                    \n",
    "    export_sucess = False \n",
    "\n",
    "    try:\n",
    "        for key, df in compilated_dict.items():   \n",
    "\n",
    "            filename = (f\"{key}.csv\")                   #ID du fichier csv = nom du dataframe\n",
    "            file_path = export_folder + filename        #Chemin de l'enregistrement\n",
    "            df.to_csv(file_path, index=True)            #enregistre le dataframe en fichier .csv\n",
    "\n",
    "        export_success = True\n",
    "        print(f\"Export des fichiers csv avec succès (voir arborescence ci-dessous): {export_folder}\")\n",
    "        return export_sucess\n",
    "    \n",
    "    except:\n",
    "        export_success = False\n",
    "        print(\"Erreur lors de l'export\")\n",
    "        return export_sucess \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESULTATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas où les widgets ne fonctionnerait pas dans le jupyter notebook :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Lancer l'aggrégation avec les paramètres souhaités et visualiser les résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Définir les paramètres\n",
    "frequency, vwmp_type = setup_values()\n",
    "\n",
    "#2) Calculer \n",
    "aggregated_dict, calculated_dict, cleaned_dict, compilated_dict = process_data(all_dataframes_dict, frequency, vwmp_type)  \n",
    "clear_output()\n",
    "\n",
    "#3) Visualiser\n",
    "#candlestick_dict = visualisation(cleaned_dict)\n",
    "\n",
    "#4) Exporter\n",
    "#export_success = export_csv(compilated_dict, frequency, vwmp_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Exporter les données avec les paramètres sélectionnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arborescence du projet : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  .\n",
    "##  ├── data\n",
    "##  │   ├── bfly.csv\n",
    "##  │   ├── bfnx.csv\n",
    "##  │   ├── bnus.csv\n",
    "##  │   ├── btrx.csv\n",
    "##  │   ├── cbse.csv\n",
    "##  │   ├── gmni.csv\n",
    "##  │   ├── itbi.csv\n",
    "##  │   ├── krkn.csv\n",
    "##  │   ├── lmax.csv\n",
    "##  │   ├── okcn.csv\n",
    "##  │   └── stmp.csv\n",
    "##  ├── livrable\n",
    "##  │   └── livrable.ipynb\n",
    "##  ├── output\n",
    "##  │   ├── Export_YYYY-MM-DD_HH-MM-SS_freq-Xmin_vwmp-X\n",
    "##  │   │   ├── df_all.csv\n",
    "##  │   │   ├── df_bfly.csv\n",
    "##  │   │   ├── df_bfnx.csv\n",
    "##  │   │   ├── df_bnus.csv\n",
    "##  │   │   ├── df_btrx.csv\n",
    "##  │   │   ├── df_cbse.csv\n",
    "##  │   │   ├── df_gmni.csv\n",
    "##  │   │   ├── df_itbi.csv\n",
    "##  │   │   ├── df_krkn.csv\n",
    "##  │   │   ├── df_lmax.csv\n",
    "##  │   │   ├── df_okcn.csv\n",
    "##  │   │   ├── df_stmp.csv\n",
    "##  │   │   └── synthese.csv\n",
    "##  └── readme.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
